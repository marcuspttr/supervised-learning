{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the generated data sets.\n",
    "train_df = pd.read_csv(Path('Resources/Generator/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/Generator/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n",
    "Because there's a lot of data and a good chunk of it is categorical I believe the logsitic regression will be a better fit and will score better.\n",
    "Our data has a binary goal (low risk loan target or not) and currently a lot of dimensions to it.\n",
    "\n",
    "I think the random tree classifier will struggle as it has a lot of decisions to make and taking the average of these will not provide as clear of a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "\n",
    "# One hot incoding the data to get split out the categorical data, dropping the first to avoid the \"dummy trap\"\n",
    "train_df_num = pd.get_dummies(train_df, drop_first= True)\n",
    "# train_df_num.head()\n",
    "\n",
    "# Splitting out the target to get X and Y data\n",
    "X_train = train_df_num.drop('target_low_risk', axis=1)\n",
    "y_train = train_df_num['target_low_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "test_df_num = pd.get_dummies(test_df, drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing dummy variables to testing set\n",
    "# Pulling the column names from the training set\n",
    "column_list = list(train_df_num.columns)\n",
    "\n",
    "# Adding any missing columns to the testing set. Filling the missing values with 0.\n",
    "test_df_num2 = test_df_num.reindex(columns=column_list,fill_value=0)\n",
    "\n",
    "X_test = test_df_num2.drop('target_low_risk', axis=1)\n",
    "y_test = test_df_num2['target_low_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.65311986863711\n",
      "Testing Data Score: 0.5078689919183327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "# Create an instance of the logistic model\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Training it.\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Previewing it's scores.\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.638664398128456\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train, y_train)\n",
    "\n",
    "print(f'Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7103448275862069\n",
      "Testing Data Score: 0.7598894087622289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1998,  353],\n",
       "       [1874,  477]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a confusion matrix to view the results of this scaled model.\n",
    "y_true = y_test\n",
    "y_predict = classifier.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_predict)\n",
    "\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic regression had a Precision of: 0.5746987951807229\n",
      "The Logistic regression had a Sensitivity of: 0.20289238621863037\n"
     ]
    }
   ],
   "source": [
    "# Pulling the model's precision and sensitivity.\n",
    "tn, fp, fn, tp = matrix.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "\n",
    "print(f'The Logistic regression had a Precision of: {precision}')\n",
    "print(f'The Logistic regression had a Sensitivity of: {sensitivity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6384517226712038\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1420,  931],\n",
       "       [2013,  338]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a confusion matrix to view the results.\n",
    "y_true = y_test\n",
    "y_predict = clf.predict(X_test)\n",
    "matrix2 = confusion_matrix(y_true, y_predict)\n",
    "\n",
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest Classifier had a Precision of: 0.26635145784081954\n",
      "The Random Forest Classifier had a Sensitivity of: 0.14376860910250958\n"
     ]
    }
   ],
   "source": [
    "# Pulling the model's precision and sensitivity.\n",
    "tn, fp, fn, tp = matrix2.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "\n",
    "print(f'The Random Forest Classifier had a Precision of: {precision}')\n",
    "print(f'The Random Forest Classifier had a Sensitivity of: {sensitivity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "Well both models didn't do so great. \n",
    "\n",
    "I was particularly shocked at the poor Sensitivity of each model (both were around .20)\n",
    "This tells me that either one isn't even sure if they are capturing all of the true values consistently.\n",
    "\n",
    "Looking at the scores, we can see the logistic function did do better with a testing data scores of .76 vs 0.64\n",
    "The logistic function improved a lot from the scaled data, whereas the random forest classifier did not change.\n",
    "Because of how tree diagrams make decisions this outcome makes sense.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
